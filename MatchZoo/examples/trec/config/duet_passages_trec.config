{
  "net_name": "DUET",
  "global":{
      "model_type": "PY",
      "weights_file": "/home/thiziri/Documents/DOCTORAT/SOFT/MatchZoo_latest1/MatchZoo/examples/trec/weights/concatenated_passages/duet_passages.trec.weights",
      "save_weights_iters": 20,
      "num_iters": 100,
      "display_interval": 10,
      "test_weights_iters": 100,
      "optimizer": "adam",
      "learning_rate": 0.001
  },
  "inputs": {
    "share": {
        "text1_corpus": "/home/thiziri/Documents/DOCTORAT/SOFT/MatchZoo_latest1/data/AP88/passageRetrieval_qrels/concatenated/fold_0/corpus_preprocessed.txt",
        "text2_corpus": "/home/thiziri/Documents/DOCTORAT/SOFT/MatchZoo_latest1/data/AP88/passageRetrieval_qrels/concatenated/fold_0/corpus_preprocessed.txt",
        "use_dpool": false,
        "embed_size": 50,
        "embed_path": "/home/thiziri/Documents/DOCTORAT/SOFT/MatchZoo_latest1/data/AP88/passageRetrieval_qrels/concatenated/fold_0/embed_glove_d50_norm",
        "vocab_size": 49062,
        "train_embed": false,
        "target_mode": "ranking",
        "text1_maxlen": 10,
        "text2_maxlen": 50
    },
    "train": {
        "input_type": "PairGenerator", 
        "phase": "TRAIN",
        "use_iter": false,
        "query_per_iter": 50,
        "batch_per_iter": 5,
        "batch_size": 100,
        "relation_file": "/home/thiziri/Documents/DOCTORAT/SOFT/MatchZoo_latest1/data/AP88/passageRetrieval_qrels/concatenated/fold_0/relation_train.txt"
    },
    "valid": {
        "input_type": "ListGenerator", 
        "phase": "EVAL",
        "batch_list": 10,
        "relation_file": "/home/thiziri/Documents/DOCTORAT/SOFT/MatchZoo_latest1/data/AP88/passageRetrieval_qrels/concatenated/fold_0/relation_valid.txt"
    },
    "test": {
        "input_type": "ListGenerator", 
        "phase": "EVAL",
        "batch_list": 10,
        "relation_file": "/home/thiziri/Documents/DOCTORAT/SOFT/MatchZoo_latest1/data/AP88/passageRetrieval_qrels/concatenated/fold_0/relation_test.txt"
    },
    "predict": {
        "input_type": "ListGenerator", 
        "phase": "PREDICT",
        "batch_list": 10,
        "relation_file": "/home/thiziri/Documents/DOCTORAT/SOFT/MatchZoo_latest1/data/AP88/passageRetrieval_qrels/concatenated/fold_0/relation_test.txt"
    }
  },
  "outputs": {
    "predict": {
      "save_format": "TREC",
      "save_path": "/home/thiziri/Documents/DOCTORAT/SOFT/MatchZoo_latest1/MatchZoo/examples/trec/predictions/passages/predict.test.duet_passages.trec.txt"
    }
  },
  "model": {
    "model_path": "./matchzoo/models/",
    "model_py": "duet_passages.DUET",
    "setting": {
        "text1_attention":false,
        "text2_attention":false,
        "context_len": 5,
        "context_num": 10,
        "passage_attention_local": false,
        "passage_attention_distributed": true,
        "lm_kernel_count": 32,
        "lm_hidden_sizes": [30],
        "dm_kernel_count": 32,
        "dm_kernel_size": 3,
        "dm_q_hidden_size": 32,
        "dm_d_mpool": 3,
        "dm_hidden_sizes": [30],
        "lm_dropout_rate": 0.5,
        "dm_dropout_rate": 0.5
    }
  },
  "losses": [ 
    {
       "object_name": "rank_hinge_loss",
       "object_params": { "margin": 1.0 }
    }
  ],
  "metrics": [ "ndcg@3", "ndcg@5", "map" ]
}

